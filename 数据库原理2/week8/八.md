```
NLTK分词


import nltk
from nltk.tokenize import word_tokenize
from nltk.tokenize import MWETokenizer

f2 = open("en_tokenize_test.txt", "r",encoding='UTF-8')

tokenizer=MWETokenizer([('in','spite','of'),('a','lot','of')],separator='_')

def preprocess(sent):
    sent = tokenizer.tokenize(nltk.word_tokenize(sent))
    #sent = nltk.word_tokenize(sent)
    return sent

for line in f2.readlines():
    line=line.strip()
    word_list=preprocess(line)
    print(word_list,"\n")

```